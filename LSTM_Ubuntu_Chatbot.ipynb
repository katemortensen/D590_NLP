{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************************************************************************/\n",
    "*    Title: LSTM Ubuntu Chatbot \n",
    "*    Author: Kate Mortensen \n",
    "*    Date: 12-11-2021\n",
    "*    Code version: 1.0\n",
    "*    Availability: NA\n",
    "*    \n",
    "* @article{lowe2015ubuntu,\n",
    "*  title={The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems},\n",
    "*  author={Lowe, Ryan and Pow, Nissan and Serban, Iulian and Pineau, Joelle},\n",
    "*  journal={arXiv preprint arXiv:1506.08909},\n",
    "*  year={2015}\n",
    "*  }\n",
    "* @article{kadlec2015improved,\n",
    "*  title={Improved deep learning baselines for ubuntu corpus dialogs},\n",
    "*  author={Kadlec, Rudolf and Schmid, Martin and Kleindienst, Jan},\n",
    "*  journal={arXiv preprint arXiv:1510.03753},\n",
    "*  year={2015}\n",
    "*  }\n",
    "* Code Inspiration\n",
    "* Author: Janina Nuber\n",
    "* Tile: Chatbot | Retrieval-based Dialog System on the Ubuntu Dialog Corpus | LSTM | PyTorch\n",
    "* Date: July 31st, 2019\n",
    "* Availability: https://github.com/Janinanu/Retrieval-based_Chatbot\n",
    "*\n",
    "***************************************************************************************/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "*The purpose of this project’s chatbot, named Chatty Kathy, is to provide technical support to Ubuntu users. Chatbots often sustain the reputation of being robotic and there is ongoing work to improve the human-like quality of responses. Retrieval-based chatbots rely on a set predefined responses to a user’s input question. There are many ways to choose the best response based on a document of input questions and responses. For example, some retrieval based chatbots produce responses based on “intent” via Tf-idf or BOW while others are based on “entity” and use POS tagging or various word embedding methods. Chatty Kathy is a very simple implementation of a retrieval-based chatbot and is judged using Ubuntu Dialog Corpus as a standard. An LSTM model is used to test whether Chatty Kathy’s responses are sufficiently human based training data from the Ubuntu Dialog Corpus.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**\n",
    "*The Ubuntu Dialog Corpus and Ubuntu Dialog Helpchat were used for this project (Lowe 2016). The Ubuntu Dialog Helpchat data was used to produce responses from Chatty Kathy while the Ubuntu Dialog Corpus was uses to train the LSTM model for retrieval-based chatbots. The Ubuntu Dialog Corpus consists of ~1 million bidirectional conversations from internal Ubuntu chat rooms, providing a substantial amount of data. The Ubuntu Dialog Helpchat data underwent data processing steps as part of the chatbot. The Ubuntu Dialog Corpus came processed and labeled (Nuber 2019). The data format is comma separated for both raw and LSTM ready data. The LSTM data and has 3 columns (user input, bot response, 1=true response/0=random response).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# Data Pre-processing Libraries \n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "# Feature Extraction Libraries\n",
    "import collections\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from nltk.probability import FreqDist \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Training\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.nn import init\n",
    "import torch.nn.utils.rnn \n",
    "import datetime\n",
    "import operator\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "In this section, the raw dialogue text from the Ubuntu Help \n",
    "Chat data set was analyzed and pre-processed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Exploratory Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many samples/rows in the dataset?  1038324\n",
      "Are there any empty entries? False\n",
      "How many empty rows (e.g. missing text entries)?  0\n",
      "Sample of text:  Hello folks, please help me a bit with the following sentence: 'Order here your personal photos or videos.' - I think the only allowed version is 'Order your personal videos or photos here.', but I'm not sure, are you?\n"
     ]
    }
   ],
   "source": [
    "def quick_analysis(path) :\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"How many samples/rows in the dataset? \", len(df.index))\n",
    "    print(\"Are there any empty entries?\", df['text'].empty==True)\n",
    "    print(\"How many empty rows (e.g. missing text entries)? \",len(df[(df['text'].isnull==True) or (df['text']==\"\")]) )\n",
    "    print(\"Sample of text: \", df['text'][0])\n",
    "\n",
    "quick_analysis(\"./Ubuntu-dialogue-corpus/dialogueText.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text: \n",
      "[\"Hello folks, please help me a bit with the following sentence: 'Order here your personal photos or videos.'\", \"- I think the only allowed version is 'Order your personal videos or photos here.\", \"', but I'm not sure, are you?\"]\n"
     ]
    }
   ],
   "source": [
    "# Pass your text into sentence tokenizer. You can specify a language parameter, for example language = \"english\"\n",
    "df = pd.read_csv(\"./dialogueText.csv\")\n",
    "text = df['text'][0]\n",
    "tokenized_text=sent_tokenize(text)\n",
    "print(\"Tokenized text: \")\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Word: \n",
      "['Hello', 'folks', ',', 'please', 'help', 'me', 'a', 'bit', 'with', 'the', 'following', 'sentence', ':', \"'Order\", 'here', 'your', 'personal', 'photos', 'or', 'videos', '.', \"'\", '-', 'I', 'think', 'the', 'only', 'allowed', 'version', 'is', \"'Order\", 'your', 'personal', 'videos', 'or', 'photos', 'here', '.', \"'\", ',', 'but', 'I', \"'m\", 'not', 'sure', ',', 'are', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokenized_word=word_tokenize(text) \n",
    "print(\"Tokenized Word: \")\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Post Tokenization Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in dataset: 626009\n",
      "Average sentence length:  24.19789172360142\n",
      "Average word length:  3.5200949980651037\n"
     ]
    }
   ],
   "source": [
    "all_text = [i for i in df['text']]\n",
    "all_sentences = sent_tokenize(text=str(all_text))\n",
    "print('Total sentences in dataset:', len(all_sentences))\n",
    "tokens_sentences = [word_tokenize(t) for t in sent_tokenize(str(all_text))]\n",
    "words = [word for sentence in tokens_sentences for word in sentence]\n",
    "# length of sentences\n",
    "sent_lengths = [len(s) for s in tokens_sentences]\n",
    "print('Average sentence length: ', sum(sent_lengths)/len(sent_lengths))\n",
    "# length of words\n",
    "word_lengths = [len(word) for word in words]\n",
    "print(\"Average word length: \", sum(word_lengths)/len(word_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lexical Diversity Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexical diversity\n",
      "\n",
      "[ :  1.0\n",
      "`` :  2.0\n",
      "Hello :  1.25\n",
      "folks :  1.0\n",
      ", :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Resource: https://python-forum.io/thread-12570.html\n",
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))\n",
    " \n",
    "def percentage(count, total):\n",
    "    return 100 * count / total\n",
    "\n",
    "print(\"lexical diversity\")\n",
    "print(\"\")\n",
    "for cat in words[0:5] :\n",
    "#for cat in nltk.corpus.brown.categories():\n",
    "    print(cat, \": \", lexical_diversity(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Frequency & Plot Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist = FreqDist(words)\n",
    "fdist.plot(10,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0cb3f3dc50>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(all_text)\n",
    "fdist.plot(10, cumulative=True, title=\"Ubuntu Messaging Board\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase & Runctuation\n",
    "words = [word.lower() for word in words if word.isalpha()]\n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in words if not w in stop_words] \n",
    "# Add stop words\n",
    "custom_list = ['like','would','could','said','one']\n",
    "stop_words.extend(custom_list)\n",
    "# Remove stop words\n",
    "stop_words = list(set(stopwords.words('english')) - set(['again', 'once', 'from']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Common Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 454092), ('to', 343862), ('the', 340437), ('a', 250718), ('it', 219521)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = collections.Counter(words)\n",
    "word_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed = [ps.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'folk', 'please', 'help', 'bit', 'following', 'sentence', 'personal', 'photo', 'video']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "print(lemmatized[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('54', 'CARDINAL'), ('55', 'CARDINAL'), ('56', 'CARDINAL'), ('57', 'CARDINAL'), ('58', 'CARDINAL'), ('59', 'CARDINAL'), ('60', 'CARDINAL'), ('Deskyop', 'PERSON'), ('61', 'CARDINAL'), ('62', 'CARDINAL'), ('63', 'CARDINAL'), ('NFS', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(str(df['text'][54:64]))\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Preprocessing & Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array(all_text)\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# The following normalization method is sufficient - chat conversations are simple lines of text and don't need further processing.\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "# must create a sample of normalized corpus - data too much for RAM\n",
    "sample_norm_corpus = norm_corpus[0:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of normalized corpus sample:  93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get bag of words features in sparse format\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(sample_norm_corpus) \n",
    "#cv_matrix = cv.fit_transform(norm_corpus) \n",
    "\n",
    "# view dense representation \n",
    "# warning might give a memory error if data is too big\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "\n",
    "# show document feature vectors\n",
    "m1 = pd.DataFrame(cv_matrix, columns=vocab)\n",
    "print(\"Length of normalized corpus sample: \", len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFid Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "tt_matrix = tt.fit_transform(cv_matrix)\n",
    "\n",
    "tt_matrix = tt_matrix.toarray()\n",
    "vocab = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(min_df=0., max_df=1., norm='l2',\n",
    "                     use_idf=True, smooth_idf=True)\n",
    "tv_matrix = tv.fit_transform(sample_norm_corpus)\n",
    "#tv_matrix = tv.fit_transform(norm_corpus)\n",
    "\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "m2 = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************************************************************************/\n",
    "* Code Inspiration\n",
    "* Author: Janina Nuber\n",
    "* Tile: Chatbot | Retrieval-based Dialog System on the Ubuntu Dialog Corpus | LSTM | PyTorch\n",
    "* Date: July 31st, 2019\n",
    "* Availability: https://github.com/Janinanu/Retrieval-based_Chatbot\n",
    "*\n",
    "***************************************************************************************/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions for Training & Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates pandas dataframe from csv file\n",
    "def create_dataframe(csvfile): \n",
    "    dataframe = pd.read_csv(csvfile)\n",
    "    return dataframe\n",
    "# Shuffles idices in df (always a good practice in ML)\n",
    "def shuffle_dataframe(dataframe):\n",
    "    dataframe.reindex(np.random.permutation(dataframe.index))\n",
    "# Create vocab list from user chats and bot responses\n",
    "def create_vocab(dataframe):\n",
    "    vocab = []\n",
    "    word_freq = {}\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        context_cell = row[\"Context\"]\n",
    "        response_cell = row[\"Utterance\"]\n",
    "        \n",
    "        train_words = str(context_cell).split() + str(response_cell).split()\n",
    "        \n",
    "        for word in train_words:\n",
    "            # potentiallly more efficient to use \"set\" \n",
    "            if word.lower() not in vocab:\n",
    "                vocab.append(word.lower())         \n",
    "                       \n",
    "            if word.lower() not in word_freq:\n",
    "                word_freq[word.lower()] = 1\n",
    "            else:\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    word_freq_sorted = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    vocab = [\"<UNK>\"] + [pair[0] for pair in word_freq_sorted]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def create_word_to_id(vocab):             \n",
    "    word_to_id = {word: id for id, word in enumerate(vocab)}\n",
    "    \n",
    "    return word_to_id\n",
    "\n",
    "\n",
    "def create_id_to_vec(word_to_id, glovefile): \n",
    "    lines = open(glovefile, 'r').readlines()\n",
    "    id_to_vec = {}\n",
    "    vector = None\n",
    "    \n",
    "    for line in lines:\n",
    "        word = line.split()[0]\n",
    "        vector = np.array(line.split()[1:], dtype='float32') #32\n",
    "        \n",
    "        if word in word_to_id:\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))\n",
    "            \n",
    "    for word, id in word_to_id.items(): \n",
    "        if word_to_id[word] not in id_to_vec:\n",
    "            v = np.zeros(*vector.shape, dtype='float32')\n",
    "            v[:] = np.random.randn(*v.shape)*0.01\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))\n",
    "            \n",
    "    embedding_dim = id_to_vec[0].shape[0]\n",
    "    \n",
    "    return id_to_vec, embedding_dim\n",
    "\n",
    "\n",
    "def load_ids_and_labels(row, word_to_id):\n",
    "    context_ids = []\n",
    "    response_ids = []\n",
    "\n",
    "    context_cell = row['Context']\n",
    "    response_cell = row['Utterance']\n",
    "    label_cell = row['Label']\n",
    "    # potentially make max_context_len into function input var\n",
    "    max_context_len = 160\n",
    "    \n",
    "    context_words = context_cell.split()\n",
    "    if len(context_words) > max_context_len:\n",
    "        context_words = context_words[:max_context_len]\n",
    "    for word in context_words:\n",
    "        if word in word_to_id:\n",
    "            context_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            context_ids.append(0) #UNK\n",
    "    \n",
    "    response_words = response_cell.split()\n",
    "    for word in response_words:\n",
    "        if word in word_to_id:\n",
    "            response_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            response_ids.append(0)\n",
    "    \n",
    "    label = np.array(label_cell).astype(np.float32)\n",
    "\n",
    "    return context_ids, response_ids, label\n",
    "\n",
    "def increase_count(correct_count, score, label):\n",
    "    if ((score.data[0][0] >= 0.5) and (label.data[0][0] == 1.0)) or ((score.data[0][0] < 0.5) and (label.data[0][0]  == 0.0)):\n",
    "       correct_count +=1  \n",
    "   \n",
    "    return correct_count\n",
    "\n",
    "def get_accuracy(correct_count, dataframe):\n",
    "    accuracy = correct_count/(len(dataframe))\n",
    "        \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Class Definitions**\n",
    "*Note: Adjustments to the original script were made due to PyTorch version differences - specifically the way in which the tensor is accessed. In addition, the author notes that the models defined below include an additional dropout layer while the in-built dropout was set to 0.0. This was done because in the case where the num_layers=1, the in-built layer, by definition, is not applied to the last layer. The author provides two links for reference of this situation: http://pytorch.org/docs/master/nn.html#torch.nn.LSTM and https://discuss.pytorch.org/t/dropout-in-lstm/7784*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "            emb_size, \n",
    "            hidden_size, \n",
    "            vocab_size, \n",
    "            p_dropout): \n",
    "    \n",
    "            super(Encoder, self).__init__()\n",
    "             \n",
    "            self.emb_size = emb_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.vocab_size = vocab_size\n",
    "            self.p_dropout = p_dropout\n",
    "       \n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "            self.lstm = nn.LSTM(self.emb_size, self.hidden_size)\n",
    "            self.dropout_layer = nn.Dropout(self.p_dropout) \n",
    "\n",
    "            self.init_weights()\n",
    "             \n",
    "    def init_weights(self):\n",
    "        init.uniform(self.lstm.weight_ih_l0, a = -0.01, b = 0.01)\n",
    "        init.orthogonal(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0.requires_grad = True\n",
    "        self.lstm.weight_hh_l0.requires_grad = True\n",
    "        \n",
    "        embedding_weights = torch.FloatTensor(self.vocab_size, self.emb_size)\n",
    "            \n",
    "        for id, vec in id_to_vec.items():\n",
    "            embedding_weights[id] = vec\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = True)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        _, (last_hidden, _) = self.lstm(embeddings) #dimensions: (num_layers * num_directions x batch_size x hidden_size)\n",
    "        last_hidden = self.dropout_layer(last_hidden[-1])#access last lstm layer, dimensions: (batch_size x hidden_size)\n",
    "\n",
    "        return last_hidden\n",
    "\n",
    "    \n",
    "class DualEncoder(nn.Module):\n",
    "     \n",
    "    def __init__(self, encoder):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = self.encoder.hidden_size\n",
    "        M = torch.FloatTensor(self.hidden_size, self.hidden_size)     \n",
    "        init.xavier_normal(M)\n",
    "        self.M = nn.Parameter(M, requires_grad = True)\n",
    "\n",
    "    def forward(self, context_tensor, response_tensor):\n",
    "        \n",
    "        context_last_hidden = self.encoder(context_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        response_last_hidden = self.encoder(response_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        \n",
    "        #context = context_last_hidden.mm(self.M).cuda()\n",
    "        context = context_last_hidden.mm(self.M) #dimensions: (batch_size x hidden_size)\n",
    "        context = context.view(-1, 1, self.hidden_size) #dimensions: (batch_size x 1 x hidden_size)\n",
    "        \n",
    "        response = response_last_hidden.view(-1, self.hidden_size, 1) #dimensions: (batch_size x hidden_size x 1)\n",
    "        \n",
    "        #score = torch.bmm(context, response).view(-1, 1).cuda()\n",
    "        score = torch.bmm(context, response).view(-1, 1) #dimensions: (batch_size x 1 x 1) and lastly --> (batch_size x 1)\n",
    "\n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Variables via Predefined Helper Functions**\n",
    "*Note: This method calls on previously defined helper functions. The desired number of examples and embedding dimensions are defined by the input arguments. Pre-trained embedding vectors were taken from GloVe file provided by author.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_variables(num_training_examples, num_validation_examples, embedding_dim):\n",
    "    \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Creating variables for training and validation...\")\n",
    "\n",
    "    training_dataframe = create_dataframe('training_%d.csv' %num_training_examples)\n",
    "    vocab = create_vocab(training_dataframe)\n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'glove.6B.%dd.txt' %embedding_dim)\n",
    "\n",
    "    validation_dataframe = create_dataframe('validation_%d.csv' %num_validation_examples)\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Variables created.\\n\")\n",
    "    \n",
    "    return training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to Create Model Instance & Set Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_model(hidden_size, p_dropout):\n",
    "    \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Calling model...\")\n",
    "\n",
    "    encoder = Encoder(\n",
    "            emb_size = emb_dim,\n",
    "            hidden_size = hidden_size,\n",
    "            vocab_size = len(vocab),\n",
    "            p_dropout = p_dropout)\n",
    "\n",
    "    dual_encoder = DualEncoder(encoder)\n",
    "\n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Model created.\\n\")\n",
    "    print(dual_encoder)\n",
    "    \n",
    "    return encoder, dual_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for Training & Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, l2_penalty, epochs): \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Starting training and validation...\\n\")\n",
    "    print(\"====================Data and Hyperparameter Overview====================\\n\")\n",
    "    print(\"Number of training examples: %d, Number of validation examples: %d\" %(len(training_dataframe), len(validation_dataframe)))\n",
    "    print(\"Learning rate: %.5f, Embedding Dimension: %d, Hidden Size: %d, Dropout: %.2f, L2:%.10f\\n\" %(learning_rate, emb_dim, encoder.hidden_size, encoder.p_dropout, l2_penalty))\n",
    "    print(\"================================Results...==============================\\n\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(dual_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    #loss_func.cuda()\n",
    "    best_validation_accuracy = 0.0\n",
    "    \n",
    "    counter = 0\n",
    "    for epoch in range(epochs): \n",
    "            counter += 1\n",
    "\n",
    "            shuffle_dataframe(training_dataframe)\n",
    "            sum_loss_training = 0.0\n",
    "            training_correct_count = 0\n",
    "            dual_encoder.train()\n",
    "\n",
    "            for index, row in training_dataframe.iterrows():            \n",
    "            \n",
    "                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "                context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1), requires_grad = False) #.cuda()\n",
    "                response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1), requires_grad = False) #.cuda()\n",
    "                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1))), requires_grad = False) #.cuda()\n",
    "                             \n",
    "                score = dual_encoder(context, response)\n",
    "                loss = loss_func(score, label)\n",
    "                #sum_loss_training += loss.data[0]\n",
    "                sum_loss_training += loss.data\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                training_correct_count = increase_count(training_correct_count, score, label)\n",
    "                                                    \n",
    "            training_accuracy = get_accuracy(training_correct_count, training_dataframe)\n",
    "            #plt.plot(epoch, training_accuracy)\n",
    "                \n",
    "            shuffle_dataframe(validation_dataframe)\n",
    "            \n",
    "            validation_correct_count = 0\n",
    "            sum_loss_validation = 0.0\n",
    "            dual_encoder.eval()\n",
    "\n",
    "            for index, row in validation_dataframe.iterrows():\n",
    "                \n",
    "                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "                context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1)) #.cuda()\n",
    "                response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1)) #.cuda()\n",
    "                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1)))) #.cuda()\n",
    "                \n",
    "                score = dual_encoder(context, response)\n",
    "                loss = loss_func(score, label)\n",
    "                #sum_loss_validation += loss.data[0]\n",
    "                sum_loss_validation += loss.data\n",
    "                validation_correct_count = increase_count(validation_correct_count, score, label)\n",
    "                    \n",
    "            validation_accuracy = get_accuracy(validation_correct_count, validation_dataframe)\n",
    "\n",
    "            if counter-1 == range(epoch) :           \n",
    "                print(str(datetime.datetime.now()).split('.')[0], \n",
    "                    \"Epoch: %d/%d\" %(epoch,epochs),  \n",
    "                    \"TrainLoss: %.3f\" %(sum_loss_training/len(training_dataframe)), \n",
    "                    \"TrainAccuracy: %.3f\" %(training_accuracy), \n",
    "                    \"ValLoss: %.3f\" %(sum_loss_validation/len(validation_dataframe)), \n",
    "                    \"ValAccuracy: %.3f\" %(validation_accuracy))\n",
    "                \n",
    "            if validation_accuracy > best_validation_accuracy:\n",
    "                best_validation_accuracy = validation_accuracy\n",
    "                torch.save(dual_encoder.state_dict(), 'saved_model_%d_examples.pt' %(len(training_dataframe)))\n",
    "                print(\"New best found and saved.\")\n",
    "              \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Training and validation epochs finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Variables for Training & Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-12 20:37:26 Creating variables for training and validation...\n",
      "2021-12-12 20:37:35 Variables created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe = creating_variables(num_training_examples = 1000, \n",
    "                                                                                                     embedding_dim = 50, \n",
    "                                                                                                     num_validation_examples = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-12 20:37:35 Calling model...\n",
      "2021-12-12 20:37:35 Model created.\n",
      "\n",
      "DualEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(6885, 50)\n",
      "    (lstm): LSTM(50, 50)\n",
      "    (dropout_layer): Dropout(p=0.85, inplace=False)\n",
      "  )\n",
      ")\n",
      "M\n",
      "encoder.embedding.weight\n",
      "encoder.lstm.weight_ih_l0\n",
      "encoder.lstm.weight_hh_l0\n",
      "encoder.lstm.bias_ih_l0\n",
      "encoder.lstm.bias_hh_l0\n"
     ]
    }
   ],
   "source": [
    "encoder, dual_encoder = creating_model(hidden_size = 50, \n",
    "                                       p_dropout = 0.85)\n",
    "\n",
    "#encoder.cuda()\n",
    "#dual_encoder.cuda\n",
    "\n",
    "for name, param in dual_encoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-12 20:32:24 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 1000, Number of validation examples: 100\n",
      "Learning rate: 0.00010, Embedding Dimension: 50, Hidden Size: 50, Dropout: 0.85, L2:0.0001000000\n",
      "\n",
      "================================Results...==============================\n",
      "\n",
      "New best found and saved.\n",
      "2021-12-12 20:37:26 Training and validation epochs finished.\n"
     ]
    }
   ],
   "source": [
    "train_model(learning_rate = 0.0001, \n",
    "            l2_penalty = 0.0001,\n",
    "            #epochs = 100)\n",
    "            epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Testing Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualEncoder(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6885, 50)\n",
       "    (lstm): LSTM(50, 50)\n",
       "    (dropout_layer): Dropout(p=0.85, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_encoder.load_state_dict(torch.load('./saved_model_1000_examples.pt'))\n",
    "dual_encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Approach**\n",
    "\n",
    "*This testing approach assumes the data is formatted in the same way as the training and validation data. For example, each line in the csv file contains user input (aka context), bot response, and label (separated with commas). The testing metric used in this approach is Accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe_same_structure = pd.read_csv('./testing_same_structure_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to Compute Scores & Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_same_structure():\n",
    "    \n",
    "    test_correct_count = 0\n",
    "\n",
    "    for index, row in test_dataframe_same_structure.iterrows():\n",
    "\n",
    "        context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)\n",
    "        context = autograd.Variable(torch.LongTensor(context_ids).view(-1,1)) #.cuda()\n",
    "        response = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1)) #.cuda()\n",
    "        label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(1,1)))) #.cuda()\n",
    "\n",
    "        score = dual_encoder(context, response)\n",
    "        test_correct_count = increase_count(test_correct_count, score, label)\n",
    "\n",
    "    test_accuracy = get_accuracy(test_correct_count, test_dataframe_same_structure)\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 1000 training examples and 1000 test examples: 0.50\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = testing_same_structure()\n",
    "print(\"Test accuracy for %d training examples and %d test examples: %.2f\" %(len(training_dataframe),len(test_dataframe_same_structure),test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chatty Kathy Chatbot**\n",
    "\n",
    "*Note: Questions and responses were pooled from the Ubuntu Dialog Corpus, as in Janina Nuber's Retrieval-Based Dialog System.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./Ubuntu-dialogue-corpus/dialogueText.csv')\n",
    "sender = list(set(df['from']))\n",
    "questions = []\n",
    "for i in range(10**3) :\n",
    "    if df['from'][i] in sender :\n",
    "        if type(df['text'][i]) is str and \"?\" in df['text'][i] :\n",
    "            questions.append(df['text'][i])\n",
    "            sender.remove(df['from'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple set of responses that capture some keywords\n",
    "responses = {\n",
    "  \"software\": \"Are you asking about Ubuntu software?\",\n",
    "  \"connection\": \"If you're having connection issues, try restarting your router.\",\n",
    "  \"printer\": \"Printer config instructions are usually at the manufactorer's website\",\n",
    "  #\"hello\" : \"Hello! I'm here to help. Do you have any other questions?\",\n",
    "  \"allocation\" : \"There may be a problem with memory allocation in the code.\",\n",
    "  \"anyone\" : \"I'll let the community handle this one.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the matching response if there is one, othwerwise return random answer\n",
    "def respond(doc) :#, bot, label):\n",
    "    doc = questions[0]\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Check if the message is in the responses\n",
    "    label = 0\n",
    "    if label < 1 :\n",
    "        for i in responses.keys() :\n",
    "            if i in filtered_tokens:\n",
    "                # Return the matching message\n",
    "                bot = responses[i]\n",
    "                label += 1\n",
    "            else:\n",
    "                # Return random message\n",
    "                bot = random.choice(list(responses.values()))\n",
    "    \n",
    "    return bot, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  fix what?\n",
      "Chatty Kathy:  If you're having connection issues, try restarting your router.\n",
      "User:  I installed the 64bit version of ubuntu and I can't open firefox(segfault) and if I try to open nautilus nothing happens and my cpu goes 100%, what can I do???\n",
      "Chatty Kathy:  There may be a problem with memory allocation in the code.\n",
      "User:  Hello Does Ubuntu have somekind of register to configure applications and os settings?\n",
      "Chatty Kathy:  I'll let the community handle this one.\n",
      "User:  how do i generate an xorg.conf file?\n",
      "Chatty Kathy:  I'll let the community handle this one.\n",
      "User:  anyone else run into issues with cd/dvd burners not identifying blank media installed?\n",
      "Chatty Kathy:  There may be a problem with memory allocation in the code.\n"
     ]
    }
   ],
   "source": [
    "# Chatty Kathy in action\n",
    "for i in questions[5:10] :\n",
    "    bot = 'default'\n",
    "    label = 0\n",
    "    print('User: ', i)\n",
    "    print('Chatty Kathy: ', respond(i)[0])\n",
    "    #print('Label: ', respond(i)[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = []\n",
    "labels = []\n",
    "for i in questions :\n",
    "    utterance.append(respond(i)[0])\n",
    "    labels.append(respond(i)[1])\n",
    "\n",
    "\n",
    "kathy_df = pd.DataFrame(data={\n",
    "    'Context': questions,\n",
    "    'Utterance' : utterance, \n",
    "    'Label' : labels\n",
    "    })\n",
    "\n",
    "kathy_df.to_csv('kathy_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 1000 training examples and 283 test examples: 1.00\n"
     ]
    }
   ],
   "source": [
    "test_dataframe_same_structure = pd.read_csv('kathy_test.csv')\n",
    "test_accuracy = testing_same_structure()\n",
    "print(\"Test accuracy for %d training examples and %d test examples: %.2f\" %(len(training_dataframe),len(test_dataframe_same_structure),test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c921acf0a0d1836cbc5cb3a246eb4c833f37b63c2d0f777fd028f80409d0b88"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
